Implementing a tiny autograd framework for training MNIST to >95% across various languages.

- [x] Python (numpy wrapper with barebones autograd)
- [ ] C (custom tensors with barebones autograd)
- [ ] HTML/CSS/Javascript (details not figured out yet)

# Python Demo
![python gif](./gif/python.gif)

# C Demo

![c gif](./gif/c.gif)

# HTML/CSS/JS Demo
